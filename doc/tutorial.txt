This file explains:

(A) how to set up an ad hoc worker installation (not deployed from a central simx source tree) that connects to a given runq server;

(B) how to set up a cental simx source tree and use it both to deploy the main simx daemons and to configure and deploy workers on multiple hosts.

(C) some tips for running aurora (as workers or otherwise).

== Basic setup for all cases ==

1. To tell simx where the aurora binaries are:

  export AURORA_CLASS_PREFIX=/path/to/aurora

(so, for example, $AURORA_CLASS_PREFIX/build/aurora.jar should exist). Do this on each host.

2. Get simx:

  git clone gitolite:simx
  
3. See the notes about ssh at the bottom of this document, which may help to make remote operations faster.


== Ad hoc worker installation ==

In simx/worker, create a file called config.yaml, but don't add it to git. This file is present in deployments, but not in the repo, because the deployment task uses some logic to pick the correct per-deployment config section out of one fiel in the worker/config dir and send that to the remote host at simx/worker/config.yaml. In effect, you are making your simx source tree act as a worker deployment as well.

The contents should be:

local: 
  runweb_host: relteq-db.dyndns.org
  runweb_port: 9097
  runq_host: relteq-db.dyndns.org
  runq_port: 9096
  workers:
    - run_class:    Run::Aurora
      count:        1 # or more, if you have more cpus
      group:        alex # your "private" worker -- use in batch request too
      user:         alex
      engine:       simulator
      cost:         0
      speed:        1
      priority:     2 # adjust as needed to force this worker to take tasks
      retry_delay:  10


For comparison, see simx/worker/config/dev.yaml. Under deployment (`rake vii-dev`), the "vii-dev:" section becomes the "local:" section of simx-dev/worker/config on vii.path, and this looks very much like above. (There is also a local entry in simx/worker/config/dev.yaml, but it's checked into git, so you probably don't want to play with it in your source tree.)

The file worker/config.yaml, if present, overrides anything in the worker/config/ dir.

This seems to be a useful way of managing several deployments but also allowing ad hoc setups.

See `rake --tasks` in the worker dir for a list of the operations that are available. If you have multiple deployment targets, you will see a block of tasks for each one. If not, you will only see task blocks for "all" and "local".

Now you can just `rake start` (alias for `rake local:start`) to start a WorkerManager and all the workers (just one in this case) that you configured. As they start, they try to connect to runq (the one specified in the config).

WorkerManager runs as a daemon; to control it, use the other rake tasks (stop, restart, stat). Note that start is a no-op if the daemon is already running. There is no direct control of workers themselves. There is no reload task--if you change config, you need to restart. Communication between the rakefile and the daemons goes via unix domain sockets that are located in simx/var/run.

The run task is like start, but does not run as a daemon, so you'll see output on the terminal and you can ctrl-c to kill it.

Now you should be able to send batch requests to runweb (on relteq-db) and see them executed locally. Remember to use the same user name and group as the worker is configured for.

You can get at the daemon's log files in three ways:

- they are in simx/var/log

- `rake log` runs less on the log file in a mode that keeps reading from the file as it changes

- `rake watch` runs tail on the log file in a similar mode

All of these rake tasks work on remotely running processes as well, which is very useful for quickly checking logs. For example, you can watch log events as they occur on vii-dev (which may be distinct from vii-pro etc., but might be on the same host) by simply saying `rake vii-dev:watch`. You can search for errors by doing `rake vii-dev:log` and using less's built-in regex searching functions. This leads us to the next section...


== Setting up an installation for managing remote deployments ==

If you want an installation of simx that can be used to manage remote deployments, as well as the local one, you will need to do one of the following:

1. If you want to switch between branches and have the current branch determine which set of deployments (for example, development vs. production) you are targeting, you need to do:

  rake git:init

in the top simx dir (not worker--they have different rakefiles). This sets up a git hook so that when you checkout a branch, the symlink simx/config.yaml (not to be confused with the config stuff under simx/worker) points to the correct file in simx/config. This contains some global config that has to be different for development, production, etc.

To configure your workers, use the appropriate file under worker/config/. Make sure you do not have a worker/config.yaml.

2. Or, more simply, if you just want to manage one set of deployments (possibly to many hosts), but do not care about development vs. production, then you can do like you did in the worker/config.yaml case: instead of a symlink, just create your own file simx/config.yaml using the simx/config/ files as a guide. (There's no need to invoke git:init.)

Use `rake config:show` to check what simx thinks the current config settings are. This should verify that your file is the one being read.

You should also edit your worker/config.yaml along the lines of worker/config/dev.yaml, so that there is a top-level key for each deployment target. (This key will become "local" when the config is copied to that target.)

Now you should be able to fire the whole thing off with:

  rake remote  # deploy code and start runq and runweb

to start runq and runweb. And to start the workers:

  cd workers

  rake all:update_aurora
    # deploy aurora jars to all remote worker installations
    # note that AURORA_CLASS_PREFIX must be defined on the remote system as
    # well as on the local one (it may be have a different value in each host)

  rake all
    # deploy worker code and config, and start the workers that are
    # configured for each host in the worker/config.yaml

If you just want to start workers on one deployment target, say vii-dev:

  cd workers
  rake vii-dev:start
  
and so on.

The watch and log commands work for remote workers:

  cd worker
  rake vii-dev:log
  rake vii-dev:watch

You can watch runq and runweb logs like this:

  cd runq
  rake watch (also, rake log)

  cd runweb
  rake watch

In addition to log files, there are also var/log/*.err. These files are sometimes written to when an error occurs before logging is set up.


== Making your daemons persist across a system boot ==

There is one more important set of rake tasks: the ones for setting up cron jobs so that the daemons get started after a reboot on each remote host. This is done with cron because non-root users can do that, but they cannot define init scripts. None of the simx functionality requires root access. For the simx daemons:

  rake remote:crontab

will set this up for you on your host (specified in config.yaml) where runq and runweb are deployed.

For the workers:

  cd worker
  rake all:crontab

will do the same for the WorkerManager on all worker hosts.

This only has to be done once per host, and you don't have to do it separately when you add more workers. They are started by WorkerManager.


== Note on ssh ==

Since the deployment process uses ssh and rsync, it will run much more smoothly if you:

1. use public key authetication

2. set up your .ssh/config so that one ssh session is used as a master, and subsequent requests are tunneled through it, without the setup delay. To do this, you must

(a) add the following in your .ssh/config:

Host *
  ControlMaster auto
  ControlPath ~/tmp/.ssh/%r@%h:%p

(b) as you start working, open one ssh session to each remote host you work with, and leave it open as long as you are working. You can just minimize these terminal windows and forget them.

== Tips for running aurora ==

We're currently using the devel branch of aurora. To build:

"ant jar"

Some of the other tasks will fail because they depend on some hard coded windows paths, but I think these are just for generating the installer for the desktop aurora, which is not relevant to us.

You'll need

AURORA_CLASS_PREFIX=/path/to/aurora

modified as needed. This is how workers find the jars.

You'll also need your TMPDIR to point to somewhere not public, because jruby seems to be paranoid. For example

TMPDIR=~/tmp
TMPDIT=/tmp/$USER

If you're testing with aurora, it might be a good idea to use a username that doesn't conflict, since runq does some matching logic. For example, if your batch requests have "user: someuser", and your workers are configured "user: someuser" as well, then your batches will go to your workers, and no wires will cross with whatever other users are doing.

See the worker/jruby-aurora package for some useful jruby scripts to test the java code independently of the whole worker infrastructure. Use "rake runsim" just to make sure your installation works before using simx workers.
